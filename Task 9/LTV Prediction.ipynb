{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757376469303,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "skCqXTOEisqC"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timedelta\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# === 0. Imports & config ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# display settings\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "sns.set(style=\"whitegrid\")\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "executionInfo": {
     "elapsed": 869,
     "status": "ok",
     "timestamp": 1757376470194,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "IquTZ-VRi3cr",
    "outputId": "693da9f8-97fa-43b4-a319-ba2c26fb1b07"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"/content/drive/MyDrive/DA project/ecommerce_customer_data_custom_ratios.csv\"\n",
    "\n",
    "# Load CSV first without parsing dates\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# List possible purchase date column names\n",
    "possible_date_cols = [\"Purchase Date\", \"Purchase_Date\", \"purchase_date\"]\n",
    "\n",
    "# Find which column exists in the CSV\n",
    "date_cols = [c for c in possible_date_cols if c in df.columns]\n",
    "\n",
    "# Parse only the existing column(s)\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Normalize all column names to lowercase + underscores\n",
    "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "# Check columns\n",
    "print(\"Columns after normalization:\", df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1757376470196,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "R_U4IdzcjMex",
    "outputId": "19a9eda9-a3e1-4370-d553-3c8397ecb366"
   },
   "outputs": [],
   "source": [
    "# === 2. Basic cleaning & required column mapping ===\n",
    "# We expect at least: customer_id, purchase_date, total_purchase_amount\n",
    "# Try common alternative names\n",
    "col_map = {}\n",
    "if \"customer_id\" not in df.columns:\n",
    "    # attempt common alternatives\n",
    "    for alt in [\"customerid\", \"customer\", \"cust_id\"]:\n",
    "        if alt in df.columns:\n",
    "            col_map[alt] = \"customer_id\"\n",
    "if \"purchase_date\" not in df.columns:\n",
    "    for alt in [\"purchase_date\", \"purchase_date\", \"order_date\", \"date\"]:\n",
    "        if alt in df.columns:\n",
    "            col_map[alt] = \"purchase_date\"\n",
    "if \"total_purchase_amount\" not in df.columns and \"order_amount\" not in df.columns and \"total_amount\" not in df.columns:\n",
    "    for alt in [\"total_purchase_amount\", \"order_amount\", \"total_amount\", \"price\", \"product_price\"]:\n",
    "        if alt in df.columns:\n",
    "            col_map[alt] = \"total_purchase_amount\"\n",
    "\n",
    "# Apply renames if found\n",
    "if col_map:\n",
    "    df = df.rename(columns=col_map)\n",
    "    print(\"Renamed cols:\", col_map)\n",
    "\n",
    "# Ensure essential columns exist\n",
    "required = [\"customer_id\", \"purchase_date\", \"total_purchase_amount\"]\n",
    "for r in required:\n",
    "    if r not in df.columns:\n",
    "        raise ValueError(f\"Required column '{r}' not found in dataset. Found columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Ensure data types\n",
    "df[\"purchase_date\"] = pd.to_datetime(df[\"purchase_date\"])\n",
    "df[\"total_purchase_amount\"] = pd.to_numeric(df[\"total_purchase_amount\"], errors=\"coerce\").fillna(0.0)\n",
    "print(\"Dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1757376470268,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "FtfGZFb1jgR7",
    "outputId": "22043e11-7ad9-4393-b33b-2410e1f83f84"
   },
   "outputs": [],
   "source": [
    "# === 3. Quick EDA (optional) ===\n",
    "print(\"Number of unique customers:\", df[\"customer_id\"].nunique())\n",
    "print(\"Date range:\", df[\"purchase_date\"].min(), \"to\", df[\"purchase_date\"].max())\n",
    "print()\n",
    "display(df.sample(5))\n",
    "print()\n",
    "print(\"Checking Duplicate value\")\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1757376470283,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "wdvuPibsjiNF",
    "outputId": "2cb7f94e-9b3f-4aa9-abe2-f843722a03f2"
   },
   "outputs": [],
   "source": [
    "# === 4. Define cutoff (observation) date and prediction horizon ===\n",
    "# Choose cutoff so that you have at least prediction_horizon days after it in the data\n",
    "# By default we'll use last date minus 365 days as cutoff to allow 12-month future window available.\n",
    "max_date = df[\"purchase_date\"].max()\n",
    "prediction_horizon_days = 365  # predict next 12 months\n",
    "cutoff_date = max_date - pd.Timedelta(days=prediction_horizon_days)\n",
    "print(\"Using cutoff_date (end of observation):\", cutoff_date.date(),\n",
    "      \" â€” prediction horizon days:\", prediction_horizon_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1757376470360,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "FPCk_XPFjmud",
    "outputId": "9d1ded01-25d2-4f95-dbcd-ed19c7a2dee1"
   },
   "outputs": [],
   "source": [
    "# === 5. Split history and future (target) windows ===\n",
    "history = df[df[\"purchase_date\"] <= cutoff_date].copy()\n",
    "future = df[(df[\"purchase_date\"] > cutoff_date) & (df[\"purchase_date\"] <= cutoff_date + pd.Timedelta(days=prediction_horizon_days))].copy()\n",
    "print(\"History rows:\", len(history), \"Future rows:\", len(future))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1757376470416,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "G0QtpjV-jma6",
    "outputId": "d803cdad-d025-4915-cfba-ee7352f7c038"
   },
   "outputs": [],
   "source": [
    "# === 6. Build target: future spend per customer in prediction window ===\n",
    "target = future.groupby(\"customer_id\")[\"total_purchase_amount\"].sum().rename(\"future_spend_12m\").reset_index()\n",
    "# include customers who appear in history but have zero future spend\n",
    "customers_history = history[\"customer_id\"].unique()\n",
    "target = pd.DataFrame({\"customer_id\": customers_history}).merge(target, on=\"customer_id\", how=\"left\")\n",
    "target[\"future_spend_12m\"] = target[\"future_spend_12m\"].fillna(0.0)\n",
    "print(\"Target rows:\", target.shape[0])\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "executionInfo": {
     "elapsed": 20849,
     "status": "ok",
     "timestamp": 1757376491268,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "V28SIb5djmDL",
    "outputId": "958860df-dc18-4cbf-af8c-0c0f98b0705b"
   },
   "outputs": [],
   "source": [
    "# === 7. Feature engineering on history window ===\n",
    "# We'll create RFM + behavioral + demographic features\n",
    "# Required columns we may use: product_category, quantity, returns, customer_age, gender, payment_method\n",
    "\n",
    "# Basic RFM\n",
    "agg_funcs = {\n",
    "    \"purchase_date\": [\"min\", \"max\", \"count\"],\n",
    "    \"total_purchase_amount\": [\"sum\", \"mean\", \"std\"]\n",
    "}\n",
    "# include quantity if present\n",
    "if \"quantity\" in history.columns:\n",
    "    agg_funcs[\"quantity\"] = [\"sum\", \"mean\"]\n",
    "if \"returns\" in history.columns:\n",
    "    agg_funcs[\"returns\"] = [\"sum\"]\n",
    "\n",
    "hist_agg = history.groupby(\"customer_id\").agg(agg_funcs)\n",
    "# flatten columns\n",
    "hist_agg.columns = [\"_\".join(col).strip() for col in hist_agg.columns.values]\n",
    "hist_agg = hist_agg.reset_index()\n",
    "# rename\n",
    "hist_agg = hist_agg.rename(columns={\n",
    "    \"purchase_date_min\": \"first_purchase_date\",\n",
    "    \"purchase_date_max\": \"last_purchase_date\",\n",
    "    \"purchase_date_count\": \"num_orders\",\n",
    "    \"total_purchase_amount_sum\": \"total_spent\",\n",
    "    \"total_purchase_amount_mean\": \"avg_order_value\",\n",
    "    \"total_purchase_amount_std\": \"std_order_value\"\n",
    "})\n",
    "# fill std NaN with 0\n",
    "hist_agg[\"std_order_value\"] = hist_agg[\"std_order_value\"].fillna(0.0)\n",
    "\n",
    "# recency and tenure\n",
    "hist_agg[\"recency_days\"] = (cutoff_date - hist_agg[\"last_purchase_date\"]).dt.days\n",
    "hist_agg[\"tenure_days\"] = (hist_agg[\"last_purchase_date\"] - hist_agg[\"first_purchase_date\"]).dt.days.clip(lower=1)\n",
    "\n",
    "# frequency per month\n",
    "hist_agg[\"orders_per_month\"] = hist_agg[\"num_orders\"] / (hist_agg[\"tenure_days\"] / 30.0)\n",
    "\n",
    "# quantity features\n",
    "if \"quantity_sum\" in hist_agg.columns and \"num_orders\" in hist_agg.columns:\n",
    "    hist_agg[\"avg_items_per_order\"] = hist_agg[\"quantity_mean\"].fillna(0.0)\n",
    "else:\n",
    "    hist_agg[\"avg_items_per_order\"] = 0.0\n",
    "\n",
    "# returns ratio\n",
    "if \"returns_sum\" in hist_agg.columns:\n",
    "    hist_agg[\"returns_ratio\"] = hist_agg[\"returns_sum\"] / hist_agg[\"num_orders\"]\n",
    "else:\n",
    "    hist_agg[\"returns_ratio\"] = 0.0\n",
    "\n",
    "# product category diversity\n",
    "if \"product_category\" in history.columns:\n",
    "    cat_div = history.groupby(\"customer_id\")[\"product_category\"].nunique().rename(\"prod_category_count\").reset_index()\n",
    "    hist_agg = hist_agg.merge(cat_div, on=\"customer_id\", how=\"left\")\n",
    "    hist_agg[\"prod_category_count\"] = hist_agg[\"prod_category_count\"].fillna(0).astype(int)\n",
    "else:\n",
    "    hist_agg[\"prod_category_count\"] = 0\n",
    "\n",
    "# preferred payment method (mode)\n",
    "if \"payment_method\" in history.columns:\n",
    "    pref_pay = history.groupby(\"customer_id\")[\"payment_method\"].agg(lambda x: x.mode().iat[0] if len(x.mode())>0 else np.nan).rename(\"preferred_payment_method\").reset_index()\n",
    "    hist_agg = hist_agg.merge(pref_pay, on=\"customer_id\", how=\"left\")\n",
    "else:\n",
    "    hist_agg[\"preferred_payment_method\"] = np.nan\n",
    "\n",
    "# demographics: age, gender (take most recent or mode)\n",
    "if \"customer_age\" in history.columns:\n",
    "    age = history.groupby(\"customer_id\")[\"customer_age\"].median().rename(\"customer_age\").reset_index()\n",
    "    hist_agg = hist_agg.merge(age, on=\"customer_id\", how=\"left\")\n",
    "else:\n",
    "    hist_agg[\"customer_age\"] = np.nan\n",
    "\n",
    "if \"gender\" in history.columns:\n",
    "    gender = history.groupby(\"customer_id\")[\"gender\"].agg(lambda x: x.mode().iat[0] if len(x.mode())>0 else np.nan).rename(\"gender\").reset_index()\n",
    "    hist_agg = hist_agg.merge(gender, on=\"customer_id\", how=\"left\")\n",
    "else:\n",
    "    hist_agg[\"gender\"] = np.nan\n",
    "\n",
    "# Fill missing numeric demographics\n",
    "hist_agg[\"customer_age\"] = hist_agg[\"customer_age\"].fillna(hist_agg[\"customer_age\"].median(skipna=True))\n",
    "hist_agg[[\"returns_ratio\"]] = hist_agg[[\"returns_ratio\"]].fillna(0.0)\n",
    "\n",
    "print(\"Feature frame shape:\", hist_agg.shape)\n",
    "hist_agg.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1757376491423,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "HpalnPzZjvlq",
    "outputId": "fec58477-2f9e-495e-e869-6a2882f6b515"
   },
   "outputs": [],
   "source": [
    "# === 8. Merge features with target & prepare model dataframe ===\n",
    "data = hist_agg.merge(target, on=\"customer_id\", how=\"left\")\n",
    "data[\"future_spend_12m\"] = data[\"future_spend_12m\"].fillna(0.0)\n",
    "\n",
    "# drop date columns that leak\n",
    "data = data.drop(columns=[c for c in [\"first_purchase_date\", \"last_purchase_date\"] if c in data.columns])\n",
    "\n",
    "print(\"Model dataset shape:\", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1757376491475,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "BnQ9LsmYj2Rt",
    "outputId": "b7d74b15-eb97-4063-ef68-61b9d0648af9"
   },
   "outputs": [],
   "source": [
    "# === 9. Prepare X (features) and y (target). Handle categorical features ===\n",
    "# Choose feature columns\n",
    "exclude = {\"customer_id\", \"future_spend_12m\"}\n",
    "feature_cols = [c for c in data.columns if c not in exclude]\n",
    "print(\"Features used:\", feature_cols)\n",
    "\n",
    "X = data[feature_cols].copy()\n",
    "y = data[\"future_spend_12m\"].copy()\n",
    "\n",
    "# Many targets are heavy-tailed; use log1p transform for modeling stability\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Simple categorical encoding: one-hot for payment_method and gender (small cardinality)\n",
    "cat_cols = [c for c in [\"preferred_payment_method\", \"gender\"] if c in X.columns]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols + [\"customer_id\"]]\n",
    "print(\"Numeric cols:\", num_cols)\n",
    "print(\"Categorical cols:\", cat_cols)\n",
    "\n",
    "# One-hot encode categorical\n",
    "X_encoded = pd.get_dummies(X, columns=cat_cols, dummy_na=True, drop_first=True)\n",
    "# Fill any remaining NaNs with 0\n",
    "X_encoded = X_encoded.fillna(0.0)\n",
    "print(\"Encoded feature shape:\", X_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1757376491528,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "LsZYhqNoj8uu",
    "outputId": "c595e43c-9759-40cc-b069-3656612add51"
   },
   "outputs": [],
   "source": [
    "# === 10. Train/validation/test split ===\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_encoded, y_log, test_size=0.3, random_state=RANDOM_STATE)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=RANDOM_STATE)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1757376492001,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "FWGyUuqEkQXv",
    "outputId": "7a202c14-2f01-430d-ad57-7bf227d8837b"
   },
   "outputs": [],
   "source": [
    "# === 11. Train XGBoost regressor with early stopping ===\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"seed\": RANDOM_STATE,\n",
    "    \"verbosity\": 1\n",
    "}\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "model = xgb.train(params, dtrain, num_boost_round=2000, early_stopping_rounds=50, evals=evals, verbose_eval=50)\n",
    "print(\"Best iteration:\", model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1757376492050,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "zgDuOFbqkThB",
    "outputId": "39e27059-0c02-4090-d136-554b3c64de08"
   },
   "outputs": [],
   "source": [
    "# === 12. Evaluation helpers and metrics (convert back from log) ===\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "def evaluate_model(mdl, X, y_log_true, label=\"set\"):\n",
    "    # Convert features to DMatrix\n",
    "    d = xgb.DMatrix(X)\n",
    "\n",
    "    # Predict\n",
    "    y_log_pred = mdl.predict(d)\n",
    "\n",
    "    # Convert from log back to actual scale\n",
    "    y_true = np.expm1(y_log_true)\n",
    "    y_pred = np.expm1(y_log_pred)\n",
    "\n",
    "    # Metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))  # <-- fixed here\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"{label} -> MAE: {mae:.2f}, RMSE: {rmse:.2f}, R2: {r2:.3f}\")\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "y_true_val, y_pred_val = evaluate_model(model, X_val, y_val, \"Validation\")\n",
    "y_true_test, y_pred_test = evaluate_model(model, X_test, y_test, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1757376492068,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "RhJAsYWDkWTw",
    "outputId": "497cd3f7-5df8-488c-ce96-3779d2cac13e"
   },
   "outputs": [],
   "source": [
    "# === 13. Business metric: Top-decile capture ===\n",
    "def topk_capture(y_true, y_pred, k=0.1):\n",
    "    n = len(y_pred)\n",
    "    topk = int(np.ceil(n * k))\n",
    "    idx = np.argsort(-y_pred)[:topk]  # top predicted\n",
    "    captured = y_true[idx].sum() / y_true.sum() if y_true.sum() > 0 else 0.0\n",
    "    return captured\n",
    "\n",
    "print(\"Top-10% capture (validation):\", topk_capture(np.array(y_true_val), np.array(y_pred_val), 0.1))\n",
    "print(\"Top-10% capture (test):\", topk_capture(np.array(y_true_test), np.array(y_pred_test), 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1757376492089,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "IgHbp6rVkXL6",
    "outputId": "f07ce9f8-e949-47bb-ed16-be600ffcaa15"
   },
   "outputs": [],
   "source": [
    "# === 14. Save model and training artifacts ===\n",
    "os.makedirs(\"artifacts\", exist_ok=True)\n",
    "joblib.dump(model, \"artifacts/xgb_ltv_model.joblib\")\n",
    "# Save feature columns order and training median (if needed)\n",
    "joblib.dump(X_encoded.columns.tolist(), \"artifacts/feature_columns.joblib\")\n",
    "print(\"Saved model and feature list to artifacts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1757376492245,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "s6wDz9IekZ2_",
    "outputId": "924205e7-6ef4-43a6-a821-131178838370"
   },
   "outputs": [],
   "source": [
    "# === 15. Create final predictions for all customers and save CSV ===\n",
    "d_all = xgb.DMatrix(X_encoded)\n",
    "pred_log_all = model.predict(d_all)\n",
    "pred_all = np.expm1(pred_log_all)\n",
    "out = pd.DataFrame({\n",
    "    \"customer_id\": data[\"customer_id\"],\n",
    "    \"predicted_ltv_12m\": pred_all,\n",
    "    \"historical_total_spent\": data[\"total_spent\"],\n",
    "    \"num_orders\": data[\"num_orders\"]\n",
    "})\n",
    "out.to_csv(\"predicted_ltv_12m.csv\", index=False)\n",
    "print(\"Saved predicted_ltv_12m.csv (rows):\", len(out))\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 950,
     "status": "ok",
     "timestamp": 1757376493193,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "E7Ud9RWQkeKy",
    "outputId": "51fed11b-8a92-4719-ac3e-254f596b323e"
   },
   "outputs": [],
   "source": [
    "# === 16. SHAP explanations (global & example local) ===\n",
    "# Note: SHAP can be slow for large models/data. Do for sample or top features.\n",
    "explainer = shap.Explainer(model)\n",
    "# compute shap values on a sample to save time\n",
    "sample_idx = np.random.choice(X_encoded.shape[0], min(500, X_encoded.shape[0]), replace=False)\n",
    "X_sample = X_encoded.iloc[sample_idx]\n",
    "shap_values = explainer(X_sample)\n",
    "\n",
    "# summary plot (global)\n",
    "shap.summary_plot(shap_values, X_sample, show=True)\n",
    "\n",
    "# to display top features numerically\n",
    "importance_df = pd.DataFrame({\n",
    "    \"feature\": X_sample.columns,\n",
    "    \"mean_abs_shap\": np.abs(shap_values.values).mean(axis=0)\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False).head(20)\n",
    "display(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1757376493647,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "I5YWPXY2ke_7",
    "outputId": "4d021175-5ea5-437f-cd09-9315fc308ac4"
   },
   "outputs": [],
   "source": [
    "# === 17. Visualizations ===\n",
    "# Actual vs Predicted (test)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_true_test, y_pred_test, alpha=0.4)\n",
    "plt.plot([0, max(y_true_test.max(), y_pred_test.max())],[0, max(y_true_test.max(), y_pred_test.max())], color='red', linewidth=1)\n",
    "plt.xlabel(\"Actual future 12m spend\")\n",
    "plt.ylabel(\"Predicted future 12m spend\")\n",
    "plt.title(\"Actual vs Predicted (Test)\")\n",
    "plt.xscale(\"symlog\")\n",
    "plt.yscale(\"symlog\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1757376493719,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "39p5wSBluQ-x",
    "outputId": "76c2efec-0f4b-4495-fffb-2a70b1c6dc5c"
   },
   "outputs": [],
   "source": [
    "# Distribution of predicted LTV\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(out[\"predicted_ltv_12m\"], bins=50, kde=False)\n",
    "plt.title(\"Distribution of Predicted LTV (12m)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 210,
     "status": "ok",
     "timestamp": 1757376493938,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "ZQpT1eyZuUVz",
    "outputId": "abeb3d19-d18b-4a04-bb50-15a4a7982c43"
   },
   "outputs": [],
   "source": [
    "# Cumulative revenue capture by decile\n",
    "deciles = out.copy()\n",
    "deciles[\"pred_pct_rank\"] = deciles[\"predicted_ltv_12m\"].rank(pct=True)\n",
    "deciles = deciles.sort_values(\"predicted_ltv_12m\", ascending=False)\n",
    "deciles[\"cum_actual\"] = deciles[\"historical_total_spent\"].cumsum()\n",
    "deciles[\"cum_actual_pct\"] = deciles[\"cum_actual\"] / deciles[\"historical_total_spent\"].sum()\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(np.arange(len(deciles))/len(deciles), deciles[\"cum_actual_pct\"])\n",
    "plt.xlabel(\"Fraction of customers (sorted by predicted LTV desc)\")\n",
    "plt.ylabel(\"Cumulative historical revenue captured\")\n",
    "plt.title(\"Lift curve (by predicted LTV)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1757376493966,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "4OZKG9bukiFT",
    "outputId": "c84d0d3f-e254-43a1-d44f-a1545b229336"
   },
   "outputs": [],
   "source": [
    "# === 18. Export model summary & README snippet (quick) ===\n",
    "with open(\"artifacts/model_info.txt\", \"w\") as f:\n",
    "    f.write(\"XGBoost LTV model\\n\")\n",
    "    f.write(f\"Trained on: {pd.Timestamp.now()}\\n\")\n",
    "    f.write(f\"Cutoff date: {cutoff_date}\\n\")\n",
    "    f.write(f\"Prediction horizon days: {prediction_horizon_days}\\n\")\n",
    "    f.write(\"Features used:\\n\")\n",
    "    for c in X_encoded.columns:\n",
    "        f.write(f\"- {c}\\n\")\n",
    "print(\"Wrote artifacts/model_info.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 76,
     "status": "ok",
     "timestamp": 1757376588801,
     "user": {
      "displayName": "siva Sakthi",
      "userId": "05517277106061795972"
     },
     "user_tz": -330
    },
    "id": "yIdjO-Zjzm8T",
    "outputId": "5cc137da-649f-46aa-a1f9-423196a3a128"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from google.colab import files\n",
    "\n",
    "# Make sure X_test is the customer-level features for test set\n",
    "# Reset index to get customer_id column if needed\n",
    "X_test_reset = X_test.reset_index()  # 'customer_id' must be part of index\n",
    "if \"customer_id\" not in X_test_reset.columns:\n",
    "    # If customer_id is in index, reset_index ensures it becomes a column\n",
    "    X_test_reset = X_test_reset.rename(columns={\"index\": \"customer_id\"})\n",
    "\n",
    "# Create predictions dataframe\n",
    "predictions_df = pd.DataFrame({\n",
    "    \"customer_id\": X_test_reset[\"customer_id\"],\n",
    "    \"predicted_ltv_12m\": y_pred_test  # Predictions from evaluate_model\n",
    "})\n",
    "\n",
    "# Save CSV\n",
    "predictions_df.to_csv(\"predicted_ltv_12m.csv\", index=False)\n",
    "files.download(\"predicted_ltv_12m.csv\")\n",
    "\n",
    "# Save trained model\n",
    "joblib.dump(model, \"xgb_ltv_model.joblib\")\n",
    "files.download(\"xgb_ltv_model.joblib\")\n",
    "\n",
    "print(\"predictions CSV and trained model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPkLQybRIcfHC5oE1wFxyWp",
   "mount_file_id": "1Gu3z2ca-dMMqkAHMF1BK9DxsWtlrY3yt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
